{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Library \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as scipy\n",
    "from scipy import spatial\n",
    "import json\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "import glob\n",
    "import cv2 as cv2\n",
    "import sklearn as sk\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import PillowWriter\n",
    "from matplotlib import cm\n",
    "\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## Utils function from https://github.com/ChrisWu1997/2D-Motion-Retargeting\n",
    "from functional.visualization import motion2video, hex2rgb\n",
    "from functional.motion import preprocess_motion2d, postprocess_motion2d, openpose2motion\n",
    "from functional.utils import ensure_dir, pad_to_height\n",
    "from model import get_autoencoder\n",
    "\n",
    "from common import config\n",
    "from dataset import get_meanpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indicating the joint connection\n",
    "connect_dict=[[0,1],[1,2],[2,3],[3,4],[4,5],[3,6],[6,7],[7,8],[8,9],[3,10],[10,11],[11,12],[12,13],[0,14],[14,15],[15,16],[16,17],[0,18],[18,19],[19,20],[20,21]]\n",
    "pose_net_joint=[4,7,8,9,11,12,13,14,15,16,18,19,20]\n",
    "open_pose_joint=[4,2,11,12,13,7,8,9,0,18,19,20,14,15,16]\n",
    "## Sliding window size\n",
    "win_size=16\n",
    "## Task and participant name\n",
    "task_list=['m01','m02','m03','m04','m05','m06','m07','m08','m09','m10']\n",
    "s_number=['s01','s02','s03','s04','s05','s06','s07','s08','s09','s10']\n",
    "e_number=['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10']\n",
    "name_dict={'m01':'deep squat','m02':'hurdle step','m03':'inline lunge','m04':'side lunge','m05':'sit to stand','m06':'leg raise','m07':\t'shoulder abduction','m08':\t'shoulder extension','m09':\t'shoulder internal-external rotation','m10':'shoulder scaption'}\n",
    "\n",
    "## Mirroring the motion if the participants are doing in the minority side\n",
    "LR_table=pd.read_csv('LR_table.csv',index_col=0)\n",
    "## Kinect position/angle data location\n",
    "kin_position_path='Segmented Movements/Segmented Movements/Kinect/Positions/'\n",
    "kin_angle_path='Segmented Movements/Segmented Movements/Kinect/Angles'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_3D_corrd_in_view(kinect_postion,kinect_angle):\n",
    "    kinect_postion=np.array(kinect_postion)\n",
    "    kinect_angle=np.array(kinect_angle)\n",
    "    kinect_postion=kinect_postion.reshape(22,3)\n",
    "    kinect_angle=kinect_angle.reshape(22,3)\n",
    "    for j_p, j_c in connect_dict:\n",
    "        rot_mat=scipy.spatial.transform.Rotation.from_euler('yxz',kinect_angle[j_p,:3]*np.pi/180).as_matrix()\n",
    "        kinect_postion[j_c,:]=kinect_postion[j_p,:]+np.matmul(rot_mat,kinect_postion[j_c,:])   \n",
    "    return kinect_postion\n",
    "\n",
    "def plot_skelton(dat,ax,**kwargs):\n",
    "    ax.invert_xaxis()\n",
    "    ax.invert_yaxis()\n",
    "    for j1,j2 in connect_dict:\n",
    "        ax.plot(dat[[j1,j2],0],-dat[[j1,j2],1],**kwargs)\n",
    "    return ax\n",
    "        \n",
    "def LR_mirror(kinect_postion,percentage,LR_table,motion): \n",
    "    for i in range(len(percentage)):\n",
    "        if LR_table[motion][percentage.tester[i]]:\n",
    "            kinect_postion[i,:,0]=-kinect_postion[i,:,0]\n",
    "    return kinect_postion\n",
    "\n",
    "def poseNet2openPose(kinect_postion):\n",
    "    chest=np.mean(kinect_postion[:,[1,4],:],axis=1).reshape(-1,1,kinect_postion.shape[2])\n",
    "    base=np.mean(kinect_postion[:,[7,10],:],axis=1).reshape(-1,1,kinect_postion.shape[2])\n",
    "    new_openpose=kinect_postion[:,[0],:]\n",
    "\n",
    "    new_openpose=np.concatenate((new_openpose,chest),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,kinect_postion[:,[4,5,6],:]),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,kinect_postion[:,[1,2,3],:]),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,base),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,kinect_postion[:,[10,11,12],:]),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,kinect_postion[:,[7,8,9],:]),axis=1)\n",
    "    return new_openpose\n",
    "\n",
    "def getPoseNet(motion):\n",
    "    return(motion[:,pose_net_joint,:])\n",
    "def getOpenPose(motion):\n",
    "    return(motion[:,open_pose_joint,:])\n",
    "def to_2D(motion):\n",
    "    return(motion[:,:,:2])\n",
    "\n",
    "def tl_preprocess_encode(motion,encoder,scale=1.2):\n",
    "    \n",
    "    motion=to_2D(motion)\n",
    "\n",
    "    if motion.shape[1] == 22:\n",
    "        motion=getOpenPose(motion)\n",
    "    elif motion.shape[1] == 13:\n",
    "        motion=poseNet2openPose(motion)\n",
    "    elif motion.shape[1] == 15:\n",
    "        motion=motion\n",
    "    else:\n",
    "        \"Not supported skeleton\"\n",
    "    for i in range(len(motion) - 1, 0, -1):\n",
    "        motion[i - 1][np.where(motion[i - 1] == 0)] = motion[i][np.where(motion[i - 1] == 0)]\n",
    "\n",
    "    motion = np.stack(motion, axis=2)\n",
    "    motion = gaussian_filter1d(motion, sigma=2, axis=-1)\n",
    "    motion = motion * scale\n",
    "    \n",
    "    motion=preprocess_motion2d(motion, mean_pose, std_pose)\n",
    "    motion=motion.to(config.device)\n",
    "    return encoder(motion).cpu().detach().numpy().squeeze()\n",
    "\n",
    "def get_sliding_wins(motion,percentage,win_size,steps=1):\n",
    "    percentage.reset_index(inplace=True,drop=True)\n",
    "    sliding_win=[]\n",
    "    sliding_percent=[]\n",
    "\n",
    "    for i in percentage.tester.unique():\n",
    "        start_id=np.where(percentage.tester == i)[0][0]\n",
    "        end_id=np.where(percentage.tester == i)[0][-1]+1\n",
    "        counter=0\n",
    "        for window in percentage.percentage.iloc[start_id:end_id].rolling(window=win_size,min_periods=win_size):\n",
    "            if len(window)<win_size:\n",
    "                continue\n",
    "            else:\n",
    "                if counter%steps == 0:\n",
    "                    sliding_win.append(motion[window.index,:,:])\n",
    "                    sliding_percent.append(window.iloc[-1])\n",
    "                    counter+=1\n",
    "                else:\n",
    "                    counter+=1\n",
    "    sliding_percent=np.array(sliding_percent)\n",
    "    return(sliding_win,sliding_percent)\n",
    "\n",
    "def label_encoding(data, segment,win_size,encoder,steps=1):\n",
    "    sliding_win, sliding_percent=get_sliding_wins(data, segment,win_size,steps=steps)\n",
    "    encode_test=[]\n",
    "    for i in range(len(sliding_win)):\n",
    "        data=tl_preprocess_encode(sliding_win[i],encoder=encoder)\n",
    "        encode_test.append(data)\n",
    "    encode_test=np.array(encode_test)\n",
    "    # sim_matrix=sk.metrics.pairwise.cosine_similarity(encode_test.reshape((-1,96*3)))\n",
    "    return((encode_test, sliding_percent) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args= argparse.Namespace(name='skeleton',model_path='model/pretrained_skeleton.pth',v1='inc_deep_squat',o='inc_deep_squat',gpu_ids=0,w1=720,h1=720,transparency=False,save_frame=1,\n",
    " fps=25,color1='#a50b69#b73b87#db9dc3',max_len=480,max_frame=480)\n",
    "config.initialize(args)\n",
    "mean_pose, std_pose = get_meanpose(config)\n",
    "net = get_autoencoder(config)\n",
    "net.load_state_dict(torch.load(args.model_path))\n",
    "net.to(config.device)\n",
    "net.eval()\n",
    "encoder=nn.Sequential(*list(net.mot_encoder.children())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motion: m10\n",
      "Testing on subject: s01\n",
      "Finish encoding\n",
      "(5752, 128, 2)\n",
      "(5752,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 128, 2)            8         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 126, 32)           224       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 63, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 61, 64)            6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                30736     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 37,353\n",
      "Trainable params: 37,349\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.0432 - mean_squared_error: 0.0432"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9136f1e14080>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m         )\n\u001b[0;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/0516_full_full_Motion_sim_poseNet_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_testing on_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msubj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sdscphd\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1141\u001b[1;33m               return_dict=True)\n\u001b[0m\u001b[0;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sdscphd\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1387\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sdscphd\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sdscphd\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[1;32m--> 895\u001b[1;33m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sdscphd\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sdscphd\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\sdscphd\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for task in task_list:\n",
    "    if task != 'm10':\n",
    "        continue\n",
    "    m_data=np.load('data/'+task+'.npy')\n",
    "    percentage=pd.read_csv('data/'+task+'.csv')\n",
    "    m_data=LR_mirror(m_data,percentage,LR_table,task)\n",
    "    m_data=getPoseNet(m_data)\n",
    "    for subj in s_number:\n",
    "        print(\"Motion: %s\"%task)\n",
    "        print('Testing on subject: %s'%subj)\n",
    "        X_train, y_train = np.array(m_data)[np.where(percentage['tester']!=subj),:,:][0],percentage.iloc[np.where(percentage['tester']!=subj)[0],:]\n",
    "        X_test, y_test = np.array(m_data)[np.where(percentage['tester']==subj),:,:][0],percentage.iloc[np.where(percentage['tester']==subj)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        encode_X_train_camera, sim_matrix_X_train_camera =  label_encoding(X_train, y_train,win_size,encoder,steps=1)\n",
    "\n",
    "\n",
    "        print(\"Finish encoding\")\n",
    "\n",
    "        X_train, y_train =sk.utils.shuffle(encode_X_train_camera,sim_matrix_X_train_camera)\n",
    "\n",
    "\n",
    "        print(X_train.shape)\n",
    "        print(y_train.shape)\n",
    "\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.Input(shape=(128,2,)))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "        model.add(keras.layers.Conv1D(32, 3, activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling1D(2))\n",
    "        model.add(keras.layers.Conv1D(64, 3, activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling1D(2))\n",
    "        model.add(keras.layers.Flatten())\n",
    "\n",
    "        model.add(keras.layers.Dense(16))\n",
    "        model.add(keras.layers.Dense(8))\n",
    "        model.add(keras.layers.Dense(4))\n",
    "        model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "        model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=['MeanSquaredError']\n",
    "        )\n",
    "        print(model.summary())\n",
    "        model.fit(x=X_train.astype('float32'),y=y_train.astype('float32'), epochs=1000,validation_split=0.2,batch_size=50)\n",
    "        model.save('model/0516_full_full_Motion_sim_poseNet_'+task+\"_testing on_\"+subj+'.h5')\n",
    "\n",
    "        X_testcamera=np.array([camera_projet(x,np.array([0,0,0.0]),np.array([0,0.0,0])) for x in X_test])\n",
    "        encode_X_test_camera, sim_matrix_X_test_camera =  label_encoding(X_testcamera, y_test,win_size,encoder)\n",
    "\n",
    "        predict=model.predict(encode_X_test_camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lb=np.arange(0.1,1,0.05)\n",
    "bound=np.arange(0.2,1,0.05)\n",
    "for task in task_list:\n",
    "    m_data=np.load('data/'+task+'.npy')\n",
    "    percentage=pd.read_csv('data/'+task+'.csv')\n",
    "    m_data=LR_mirror(m_data,percentage,LR_table,task)\n",
    "    m_data=getOpenPose(m_data)\n",
    "    space=pd.DataFrame(index=lb,columns=bound)\n",
    "    tot_time=0\n",
    "    tot_frame=0\n",
    "    for subj in s_number:\n",
    "        print(\"Motion: %s\"%task)\n",
    "        print('Testing on subject: %s'%subj)\n",
    "        X_train, y_train = np.array(m_data)[np.where(percentage['tester']!=subj),:,:][0],percentage.iloc[np.where(percentage['tester']!=subj)[0],:]\n",
    "        X_test, y_test = np.array(m_data)[np.where(percentage['tester']==subj),:,:][0],percentage.iloc[np.where(percentage['tester']==subj)]\n",
    "\n",
    "        model=tf.keras.models.load_model('0516_model/0516_full_full_Motion_sim_poseNet_'+task+\"_testing on_\"+subj+'.h5')\n",
    "\n",
    "        start=time.time()\n",
    "        encode_X_test_camera, sim_matrix_X_test_camera =  label_encoding(X_test, y_test,win_size,encoder)\n",
    "        predict=model.predict(encode_X_test_camera)\n",
    "        end=time.time()\n",
    "        perfor_t[task][subj]=(end-start)/encode_X_test_camera.shape[0]\n",
    "        perfor_mse[task][subj]=sk.metrics.mean_squared_error(sim_matrix_X_test_camera,predict)\n",
    "        frame_time= np.where(sim_matrix_X_test_camera==1)[0]\n",
    "        frame_time=np.concatenate((frame_time,[len(sim_matrix_X_test_camera)]))\n",
    "        previous_best=[]\n",
    "        current_frame=[]\n",
    "        for l in lb:\n",
    "            for ran in bound:\n",
    "                if l+ran >1:\n",
    "                    continue\n",
    "                count=0\n",
    "                low_swtich=True\n",
    "                high_switch=False\n",
    "                current_frame=[]\n",
    "                for i in range(len(predict)):\n",
    "                    if predict[i]<l and low_swtich:\n",
    "                        high_switch=True\n",
    "                        low_swtich=False\n",
    "                    if predict[i]>l+ran and high_switch:\n",
    "                        count=count+1\n",
    "                        high_switch=False\n",
    "                        low_swtich=True\n",
    "                        current_frame.append(i)\n",
    "                if perfor[task][subj] is np.nan or (np.abs(count-10)<np.abs(perfor[task][subj]-10)) or (np.abs(count-10)==np.abs(perfor[task][subj]-10) and ran> perfor_r[task][subj]):       \n",
    "                    perfor[task][subj]= count\n",
    "                    perfor_lb[task][subj]=l\n",
    "                    perfor_r[task][subj]=ran\n",
    "\n",
    "        if len(previous_best) ==10:\n",
    "            perfor_t_diff[task][subj]=np.mean(np.abs(np.array(previous_best)-frame_time)) \n",
    "        fig, ax= plt.subplots()\n",
    "        ax.set_title(\"Motion: \"+name_dict[task]+\" testing on \"+subj)\n",
    "        ax.hlines([perfor_lb[task][subj],perfor_lb[task][subj]+perfor_r[task][subj]],0,len(predict))\n",
    "        ax.annotate('Lower bound',(10,perfor_lb[task][subj]),xytext=(30,perfor_lb[task][subj]+0.1),arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=0.2\"))\n",
    "        ax.annotate('Upper bound',(10,perfor_lb[task][subj]+perfor_r[task][subj]),xytext=(30,perfor_lb[task][subj]+perfor_r[task][subj]-0.1),arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=0.2\"))\n",
    "        ax.plot(predict)\n",
    "        ax.plot(sim_matrix_X_test_camera)\n",
    "        ax.set_xlabel(\"Frame\")\n",
    "        ax.set_ylabel(\"Progress\")\n",
    "        ax.legend(['Predicted value','Groud Truth'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select task and subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion='m05'\n",
    "subject='s03'\n",
    "output_file='demo3.gif'\n",
    "lower=0.2\n",
    "upper=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data=np.load('data/'+motion+'.npy')\n",
    "percentage=pd.read_csv('data/'+motion+'.csv')\n",
    "m_data=LR_mirror(m_data,percentage,LR_table,motion)\n",
    "X_test, y_test = np.array(m_data)[np.where(percentage['tester']==subject),:,:][0],percentage.iloc[np.where(percentage['tester']==subject)]\n",
    "X_test_op=getOpenPose(X_test)\n",
    "model=tf.keras.models.load_model('0516_model/0516_full_full_Motion_sim_poseNet_'+motion+\"_testing on_\"+subject+'.h5')\n",
    "encode_X_test_camera, sim_matrix_X_test_camera =  label_encoding(X_test_op, y_test,win_size,encoder)\n",
    "predict=model.predict(encode_X_test_camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 1 at frame 90\n",
      "Count 2 at frame 190\n",
      "Count 3 at frame 288\n",
      "Count 4 at frame 391\n",
      "Count 5 at frame 496\n",
      "Count 6 at frame 602\n",
      "Count 7 at frame 728\n",
      "Count 8 at frame 843\n",
      "Count 9 at frame 951\n",
      "Count 10 at frame 1057\n"
     ]
    }
   ],
   "source": [
    "fig, ax= plt.subplots()\n",
    "count=0\n",
    "low_swtich=True\n",
    "high_switch=False\n",
    "ims = []\n",
    "for i in range(len(X_test)):\n",
    "    ## Plot skeleton\n",
    "    ske=[]\n",
    "    for j1,j2 in connect_dict:\n",
    "        line,=ax.plot(X_test[i][[j1,j2],0],X_test[i][[j1,j2],1],c=\"#81b941\")\n",
    "        ske.append(line)\n",
    "    ## Counting\n",
    "    if i-16 > 0 and i-16<len(predict): \n",
    "        if predict[i-16]<lower and low_swtich:\n",
    "            high_switch=True\n",
    "            low_swtich=False\n",
    "        if predict[i-16]>upper and high_switch:\n",
    "            count=count+1\n",
    "            high_switch=False\n",
    "            low_swtich=True\n",
    "            print(\"Count %s at frame %s\"%(count,i))\n",
    "    p_text=ax.text(-60,60,\"Predict: %.2f\"%predict[i-16])\n",
    "    c_text=ax.text(-60,40,\"Count: %s\"%count)\n",
    "    ske.append(p_text)\n",
    "    ske.append(c_text)\n",
    "    ims.append(ske)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=33, blit=True,\n",
    "                                repeat_delay=1)\n",
    "\n",
    "writer = PillowWriter(fps=33)\n",
    "ani.save(output_file, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
