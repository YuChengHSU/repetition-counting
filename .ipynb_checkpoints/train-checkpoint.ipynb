{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.4\n"
     ]
    }
   ],
   "source": [
    "## Library \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as scipy\n",
    "from scipy import spatial\n",
    "import json\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "import glob\n",
    "import cv2 as cv2\n",
    "import sklearn as sk\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import PillowWriter\n",
    "from matplotlib import cm\n",
    "\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## Utils function from https://github.com/ChrisWu1997/2D-Motion-Retargeting\n",
    "from functional.visualization import motion2video, hex2rgb\n",
    "from functional.motion import preprocess_motion2d, postprocess_motion2d, openpose2motion\n",
    "from functional.utils import ensure_dir, pad_to_height\n",
    "from model import get_autoencoder\n",
    "\n",
    "from common import config\n",
    "from dataset import get_meanpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indicating the joint connection\n",
    "connect_dict=[[0,1],[1,2],[2,3],[3,4],[4,5],[3,6],[6,7],[7,8],[8,9],[3,10],[10,11],[11,12],[12,13],[0,14],[14,15],[15,16],[16,17],[0,18],[18,19],[19,20],[20,21]]\n",
    "pose_net_joint=[4,7,8,9,11,12,13,14,15,16,18,19,20]\n",
    "open_pose_joint=[4,2,11,12,13,7,8,9,0,18,19,20,14,15,16]\n",
    "## Sliding window size\n",
    "win_size=16\n",
    "## Task and participant name\n",
    "task_list=['m01','m02','m03','m04','m05','m06','m07','m08','m09','m10']\n",
    "s_number=['s01','s02','s03','s04','s05','s06','s07','s08','s09','s10']\n",
    "e_number=['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10']\n",
    "name_dict={'m01':'deep squat','m02':'hurdle step','m03':'inline lunge','m04':'side lunge','m05':'sit to stand','m06':'leg raise','m07':\t'shoulder abduction','m08':\t'shoulder extension','m09':\t'shoulder internal-external rotation','m10':'shoulder scaption'}\n",
    "\n",
    "## Mirroring the motion if the participants are doing in the minority side\n",
    "LR_table=pd.read_csv('LR_table.csv',index_col=0)\n",
    "## Kinect position/angle data location\n",
    "kin_position_path='Segmented Movements/Segmented Movements/Kinect/Positions/'\n",
    "kin_angle_path='Segmented Movements/Segmented Movements/Kinect/Angles'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_3D_corrd_in_view(kinect_postion,kinect_angle):\n",
    "    kinect_postion=np.array(kinect_postion)\n",
    "    kinect_angle=np.array(kinect_angle)\n",
    "    kinect_postion=kinect_postion.reshape(22,3)\n",
    "    kinect_angle=kinect_angle.reshape(22,3)\n",
    "    for j_p, j_c in connect_dict:\n",
    "        rot_mat=scipy.spatial.transform.Rotation.from_euler('yxz',kinect_angle[j_p,:3]*np.pi/180).as_matrix()\n",
    "        kinect_postion[j_c,:]=kinect_postion[j_p,:]+np.matmul(rot_mat,kinect_postion[j_c,:])   \n",
    "    return kinect_postion\n",
    "\n",
    "def plot_skelton(dat,ax,**kwargs):\n",
    "    ax.invert_xaxis()\n",
    "    ax.invert_yaxis()\n",
    "    for j1,j2 in connect_dict:\n",
    "        ax.plot(dat[[j1,j2],0],-dat[[j1,j2],1],**kwargs)\n",
    "    return ax\n",
    "        \n",
    "def LR_mirror(kinect_postion,percentage,LR_table,motion): \n",
    "    for i in range(len(percentage)):\n",
    "        if LR_table[motion][percentage.tester[i]]:\n",
    "            kinect_postion[i,:,0]=-kinect_postion[i,:,0]\n",
    "    return kinect_postion\n",
    "\n",
    "def poseNet2openPose(kinect_postion):\n",
    "    chest=np.mean(kinect_postion[:,[1,4],:],axis=1).reshape(-1,1,kinect_postion.shape[2])\n",
    "    base=np.mean(kinect_postion[:,[7,10],:],axis=1).reshape(-1,1,kinect_postion.shape[2])\n",
    "    new_openpose=kinect_postion[:,[0],:]\n",
    "\n",
    "    new_openpose=np.concatenate((new_openpose,chest),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,kinect_postion[:,[4,5,6],:]),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,kinect_postion[:,[1,2,3],:]),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,base),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,kinect_postion[:,[10,11,12],:]),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,kinect_postion[:,[7,8,9],:]),axis=1)\n",
    "    return new_openpose\n",
    "\n",
    "def getPoseNet(motion):\n",
    "    return(motion[:,pose_net_joint,:])\n",
    "def getOpenPose(motion):\n",
    "    return(motion[:,open_pose_joint,:])\n",
    "def to_2D(motion):\n",
    "    return(motion[:,:,:2])\n",
    "\n",
    "def tl_preprocess_encode(motion,encoder,scale=1.2):\n",
    "    \n",
    "    motion=to_2D(motion)\n",
    "\n",
    "    if motion.shape[1] == 22:\n",
    "        motion=getOpenPose(motion)\n",
    "    elif motion.shape[1] == 13:\n",
    "        motion=poseNet2openPose(motion)\n",
    "    elif motion.shape[1] == 15:\n",
    "        motion=motion\n",
    "    else:\n",
    "        \"Not supported skeleton\"\n",
    "    for i in range(len(motion) - 1, 0, -1):\n",
    "        motion[i - 1][np.where(motion[i - 1] == 0)] = motion[i][np.where(motion[i - 1] == 0)]\n",
    "\n",
    "    motion = np.stack(motion, axis=2)\n",
    "    motion = gaussian_filter1d(motion, sigma=2, axis=-1)\n",
    "    motion = motion * scale\n",
    "    \n",
    "    motion=preprocess_motion2d(motion, mean_pose, std_pose)\n",
    "    motion=motion.to(config.device)\n",
    "    return encoder(motion).cpu().detach().numpy().squeeze()\n",
    "\n",
    "def get_sliding_wins(motion,percentage,win_size,steps=1):\n",
    "    percentage.reset_index(inplace=True,drop=True)\n",
    "    sliding_win=[]\n",
    "    sliding_percent=[]\n",
    "\n",
    "    for i in percentage.tester.unique():\n",
    "        start_id=np.where(percentage.tester == i)[0][0]\n",
    "        end_id=np.where(percentage.tester == i)[0][-1]+1\n",
    "        counter=0\n",
    "        for window in percentage.percentage.iloc[start_id:end_id].rolling(window=win_size,min_periods=win_size):\n",
    "            if len(window)<win_size:\n",
    "                continue\n",
    "            else:\n",
    "                if counter%steps == 0:\n",
    "                    sliding_win.append(motion[window.index,:,:])\n",
    "                    sliding_percent.append(window.iloc[-1])\n",
    "                    counter+=1\n",
    "                else:\n",
    "                    counter+=1\n",
    "    sliding_percent=np.array(sliding_percent)\n",
    "    return(sliding_win,sliding_percent)\n",
    "\n",
    "def label_encoding(data, segment,win_size,encoder,steps=1):\n",
    "    sliding_win, sliding_percent=get_sliding_wins(data, segment,win_size,steps=steps)\n",
    "    encode_test=[]\n",
    "    for i in range(len(sliding_win)):\n",
    "        data=tl_preprocess_encode(sliding_win[i],encoder=encoder)\n",
    "        encode_test.append(data)\n",
    "    encode_test=np.array(encode_test)\n",
    "    # sim_matrix=sk.metrics.pairwise.cosine_similarity(encode_test.reshape((-1,96*3)))\n",
    "    return((encode_test, sliding_percent) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args= argparse.Namespace(name='skeleton',model_path='model/pretrained_skeleton.pth',v1='inc_deep_squat',o='inc_deep_squat',gpu_ids=0,w1=720,h1=720,transparency=False,save_frame=1,\n",
    " fps=25,color1='#a50b69#b73b87#db9dc3',max_len=480,max_frame=480)\n",
    "config.initialize(args)\n",
    "mean_pose, std_pose = get_meanpose(config)\n",
    "net = get_autoencoder(config)\n",
    "net.load_state_dict(torch.load(args.model_path))\n",
    "net.to(config.device)\n",
    "net.eval()\n",
    "encoder=nn.Sequential(*list(net.mot_encoder.children())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in task_list:\n",
    "    if task != 'm10':\n",
    "        continue\n",
    "    m_data=np.load('data/'+task+'.npy')\n",
    "    percentage=pd.read_csv('data/'+task+'.csv')\n",
    "    m_data=LR_mirror(m_data,percentage,LR_table,task)\n",
    "    m_data=getPoseNet(m_data)\n",
    "    for subj in s_number:\n",
    "        print(\"Motion: %s\"%task)\n",
    "        print('Testing on subject: %s'%subj)\n",
    "        X_train, y_train = np.array(m_data)[np.where(percentage['tester']!=subj),:,:][0],percentage.iloc[np.where(percentage['tester']!=subj)[0],:]\n",
    "        X_test, y_test = np.array(m_data)[np.where(percentage['tester']==subj),:,:][0],percentage.iloc[np.where(percentage['tester']==subj)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        encode_X_train_camera, sim_matrix_X_train_camera =  label_encoding(X_train, y_train,win_size,encoder,steps=1)\n",
    "\n",
    "\n",
    "        print(\"Finish encoding\")\n",
    "\n",
    "        X_train, y_train =sk.utils.shuffle(encode_X_train_camera,sim_matrix_X_train_camera)\n",
    "\n",
    "\n",
    "        print(X_train.shape)\n",
    "        print(y_train.shape)\n",
    "\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.Input(shape=(128,2,)))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "        model.add(keras.layers.Conv1D(32, 3, activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling1D(2))\n",
    "        model.add(keras.layers.Conv1D(64, 3, activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling1D(2))\n",
    "        model.add(keras.layers.Flatten())\n",
    "\n",
    "        model.add(keras.layers.Dense(16))\n",
    "        model.add(keras.layers.Dense(8))\n",
    "        model.add(keras.layers.Dense(4))\n",
    "        model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "        model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=['MeanSquaredError']\n",
    "        )\n",
    "        print(model.summary())\n",
    "        model.fit(x=X_train.astype('float32'),y=y_train.astype('float32'), epochs=1000,validation_split=0.2,batch_size=50)\n",
    "        model.save('model/0516_full_full_Motion_sim_poseNet_'+task+\"_testing on_\"+subj+'.h5')\n",
    "\n",
    "        X_testcamera=np.array([camera_projet(x,np.array([0,0,0.0]),np.array([0,0.0,0])) for x in X_test])\n",
    "        encode_X_test_camera, sim_matrix_X_test_camera =  label_encoding(X_testcamera, y_test,win_size,encoder)\n",
    "\n",
    "        predict=model.predict(encode_X_test_camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lb=np.arange(0.1,1,0.05)\n",
    "bound=np.arange(0.2,1,0.05)\n",
    "for task in task_list:\n",
    "    m_data=np.load('data/'+task+'.npy')\n",
    "    percentage=pd.read_csv('data/'+task+'.csv')\n",
    "    m_data=LR_mirror(m_data,percentage,LR_table,task)\n",
    "    m_data=getOpenPose(m_data)\n",
    "    space=pd.DataFrame(index=lb,columns=bound)\n",
    "    tot_time=0\n",
    "    tot_frame=0\n",
    "    for subj in s_number:\n",
    "        print(\"Motion: %s\"%task)\n",
    "        print('Testing on subject: %s'%subj)\n",
    "        X_train, y_train = np.array(m_data)[np.where(percentage['tester']!=subj),:,:][0],percentage.iloc[np.where(percentage['tester']!=subj)[0],:]\n",
    "        X_test, y_test = np.array(m_data)[np.where(percentage['tester']==subj),:,:][0],percentage.iloc[np.where(percentage['tester']==subj)]\n",
    "\n",
    "        model=tf.keras.models.load_model('0516_model/0516_full_full_Motion_sim_poseNet_'+task+\"_testing on_\"+subj+'.h5')\n",
    "\n",
    "        start=time.time()\n",
    "        encode_X_test_camera, sim_matrix_X_test_camera =  label_encoding(X_test, y_test,win_size,encoder)\n",
    "        predict=model.predict(encode_X_test_camera)\n",
    "        end=time.time()\n",
    "        perfor_t[task][subj]=(end-start)/encode_X_test_camera.shape[0]\n",
    "        perfor_mse[task][subj]=sk.metrics.mean_squared_error(sim_matrix_X_test_camera,predict)\n",
    "        frame_time= np.where(sim_matrix_X_test_camera==1)[0]\n",
    "        frame_time=np.concatenate((frame_time,[len(sim_matrix_X_test_camera)]))\n",
    "        previous_best=[]\n",
    "        current_frame=[]\n",
    "        for l in lb:\n",
    "            for ran in bound:\n",
    "                if l+ran >1:\n",
    "                    continue\n",
    "                count=0\n",
    "                low_swtich=True\n",
    "                high_switch=False\n",
    "                current_frame=[]\n",
    "                for i in range(len(predict)):\n",
    "                    if predict[i]<l and low_swtich:\n",
    "                        high_switch=True\n",
    "                        low_swtich=False\n",
    "                    if predict[i]>l+ran and high_switch:\n",
    "                        count=count+1\n",
    "                        high_switch=False\n",
    "                        low_swtich=True\n",
    "                        current_frame.append(i)\n",
    "                if perfor[task][subj] is np.nan or (np.abs(count-10)<np.abs(perfor[task][subj]-10)) or (np.abs(count-10)==np.abs(perfor[task][subj]-10) and ran> perfor_r[task][subj]):       \n",
    "                    perfor[task][subj]= count\n",
    "                    perfor_lb[task][subj]=l\n",
    "                    perfor_r[task][subj]=ran\n",
    "\n",
    "        if len(previous_best) ==10:\n",
    "            perfor_t_diff[task][subj]=np.mean(np.abs(np.array(previous_best)-frame_time)) \n",
    "        fig, ax= plt.subplots()\n",
    "        ax.set_title(\"Motion: \"+name_dict[task]+\" testing on \"+subj)\n",
    "        ax.hlines([perfor_lb[task][subj],perfor_lb[task][subj]+perfor_r[task][subj]],0,len(predict))\n",
    "        ax.annotate('Lower bound',(10,perfor_lb[task][subj]),xytext=(30,perfor_lb[task][subj]+0.1),arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=0.2\"))\n",
    "        ax.annotate('Upper bound',(10,perfor_lb[task][subj]+perfor_r[task][subj]),xytext=(30,perfor_lb[task][subj]+perfor_r[task][subj]-0.1),arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=0.2\"))\n",
    "        ax.plot(predict)\n",
    "        ax.plot(sim_matrix_X_test_camera)\n",
    "        ax.set_xlabel(\"Frame\")\n",
    "        ax.set_ylabel(\"Progress\")\n",
    "        ax.legend(['Predicted value','Groud Truth'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select task and subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion='m05'\n",
    "subject='s03'\n",
    "output_file='demo3.gif'\n",
    "lower=0.2\n",
    "upper=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data=np.load('data/'+motion+'.npy')\n",
    "percentage=pd.read_csv('data/'+motion+'.csv')\n",
    "m_data=LR_mirror(m_data,percentage,LR_table,motion)\n",
    "X_test, y_test = np.array(m_data)[np.where(percentage['tester']==subject),:,:][0],percentage.iloc[np.where(percentage['tester']==subject)]\n",
    "X_test_op=getOpenPose(X_test)\n",
    "model=tf.keras.models.load_model('0516_model/0516_full_full_Motion_sim_poseNet_'+motion+\"_testing on_\"+subject+'.h5')\n",
    "encode_X_test_camera, sim_matrix_X_test_camera =  label_encoding(X_test_op, y_test,win_size,encoder)\n",
    "predict=model.predict(encode_X_test_camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 1 at frame 90\n",
      "Count 2 at frame 190\n",
      "Count 3 at frame 288\n",
      "Count 4 at frame 391\n",
      "Count 5 at frame 496\n",
      "Count 6 at frame 602\n",
      "Count 7 at frame 728\n",
      "Count 8 at frame 843\n",
      "Count 9 at frame 951\n",
      "Count 10 at frame 1057\n"
     ]
    }
   ],
   "source": [
    "fig, ax= plt.subplots()\n",
    "count=0\n",
    "low_swtich=True\n",
    "high_switch=False\n",
    "ims = []\n",
    "for i in range(len(X_test)):\n",
    "    ## Plot skeleton\n",
    "    ske=[]\n",
    "    for j1,j2 in connect_dict:\n",
    "        line,=ax.plot(X_test[i][[j1,j2],0],X_test[i][[j1,j2],1],c=\"#81b941\")\n",
    "        ske.append(line)\n",
    "    ## Counting\n",
    "    if i-16 > 0 and i-16<len(predict): \n",
    "        if predict[i-16]<lower and low_swtich:\n",
    "            high_switch=True\n",
    "            low_swtich=False\n",
    "        if predict[i-16]>upper and high_switch:\n",
    "            count=count+1\n",
    "            high_switch=False\n",
    "            low_swtich=True\n",
    "            print(\"Count %s at frame %s\"%(count,i))\n",
    "    p_text=ax.text(-60,60,\"Predict: %.2f\"%predict[i-16])\n",
    "    c_text=ax.text(-60,40,\"Count: %s\"%count)\n",
    "    ske.append(p_text)\n",
    "    ske.append(c_text)\n",
    "    ims.append(ske)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=33, blit=True,\n",
    "                                repeat_delay=1)\n",
    "\n",
    "writer = PillowWriter(fps=33)\n",
    "ani.save(output_file, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
