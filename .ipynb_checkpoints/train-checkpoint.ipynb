{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Library \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as scipy\n",
    "from scipy import spatial\n",
    "import json\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "import glob\n",
    "import cv2 as cv2\n",
    "import sklearn as sk\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "print(pd.__version__)\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from matplotlib import cm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "## Utils function from https://github.com/ChrisWu1997/2D-Motion-Retargeting\n",
    "from functional.visualization import motion2video, hex2rgb\n",
    "from functional.motion import preprocess_motion2d, postprocess_motion2d, openpose2motion\n",
    "from functional.utils import ensure_dir, pad_to_height\n",
    "from model import get_autoencoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from common import config\n",
    "from dataset import get_meanpose\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indicating the joint connection\n",
    "connect_dict=[[0,1],[1,2],[2,3],[3,4],[4,5],[3,6],[6,7],[7,8],[8,9],[3,10],[10,11],[11,12],[12,13],[0,14],[14,15],[15,16],[16,17],[0,18],[18,19],[19,20],[20,21]]\n",
    "pose_net_joint=[4,7,8,9,11,12,13,14,15,16,18,19,20]\n",
    "open_pose_joint=[4,2,11,12,13,7,8,9,0,18,19,20,14,15,16]\n",
    "## Sliding window size\n",
    "win_size=16\n",
    "## Output file directory\n",
    "output_dir='inc_deep_squat'\n",
    "## Task and participant name\n",
    "task_list=['m01','m02','m03','m04','m05','m06','m07','m08','m09','m10']\n",
    "s_number=['s01','s02','s03','s04','s05','s06','s07','s08','s09','s10']\n",
    "e_number=['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10']\n",
    "## Mirroring the motion if the participants are doing in the minority side\n",
    "LR_table=pd.read_csv('LR_table.csv',index_col=0)\n",
    "## Kinect position/angle data location\n",
    "kin_position_path='Segmented Movements/Segmented Movements/Kinect/Positions/'\n",
    "kin_angle_path='Segmented Movements/Segmented Movements/Kinect/Angles'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_3D_corrd_in_view(kinect_postion,kinect_angle):\n",
    "    kinect_postion=np.array(kinect_postion)\n",
    "    kinect_angle=np.array(kinect_angle)\n",
    "    kinect_postion=kinect_postion.reshape(22,3)\n",
    "    kinect_angle=kinect_angle.reshape(22,3)\n",
    "    for j_p, j_c in connect_dict:\n",
    "        rot_mat=scipy.spatial.transform.Rotation.from_euler('yxz',kinect_angle[j_p,:3]*np.pi/180).as_matrix()\n",
    "        kinect_postion[j_c,:]=kinect_postion[j_p,:]+np.matmul(rot_mat,kinect_postion[j_c,:])   \n",
    "    return kinect_postion\n",
    "\n",
    "def plot_skelton(dat,**kwargs):\n",
    "    plt.annotate('Waist',(dat[0,0],-dat[0,1]))\n",
    "    plt.annotate('head',(dat[4,0],-dat[4,1]))\n",
    "    plt.annotate('left hand',(dat[9,0],-dat[9,1]))\n",
    "    plt.annotate('Right hand',(dat[13,0],-dat[13,1]))\n",
    "    plt.annotate('Left leg',(dat[17,0],-dat[17,1]))\n",
    "    for j1,j2 in connect_dict:\n",
    "        plt.plot(dat[[j1,j2],0],-dat[[j1,j2],1],**kwargs)\n",
    "        \n",
    "def LR_mirror(kinect_postion,percentage,LR_table,motion): \n",
    "    for i in range(len(percentage)):\n",
    "        if LR_table[motion][percentage.tester[i]]:\n",
    "            kinect_postion[i,:,0]=-kinect_postion[i,:,0]\n",
    "    return kinect_postion\n",
    "\n",
    "def poseNet2openPose(kinect_postion):\n",
    "    chest=np.mean(kinect_postion[:,[1,4],:],axis=1).reshape(-1,1,kinect_postion.shape[2])\n",
    "    base=np.mean(kinect_postion[:,[7,10],:],axis=1).reshape(-1,1,kinect_postion.shape[2])\n",
    "    new_openpose=kinect_postion[:,[0],:]\n",
    "\n",
    "    new_openpose=np.concatenate((new_openpose,chest),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,kinect_postion[:,[4,5,6],:]),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,kinect_postion[:,[1,2,3],:]),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,base),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,kinect_postion[:,[10,11,12],:]),axis=1)\n",
    "    new_openpose=np.concatenate((new_openpose,kinect_postion[:,[7,8,9],:]),axis=1)\n",
    "    return new_openpose\n",
    "\n",
    "def getPoseNet(motion):\n",
    "    return(motion[:,pose_net_joint,:])\n",
    "def getOpenPose(motion):\n",
    "    return(motion[:,open_pose_joint,:])\n",
    "def to_2D(motion):\n",
    "    return(motion[:,:,:2])\n",
    "\n",
    "def tl_preprocess_encode(motion,encoder,scale=1.2):\n",
    "    \n",
    "    motion=to_2D(motion)\n",
    "\n",
    "    if motion.shape[1] == 22:\n",
    "        motion=getOpenPose(motion)\n",
    "    elif motion.shape[1] == 13:\n",
    "        motion=poseNet2openPose(motion)\n",
    "    elif motion.shape[1] == 15:\n",
    "        motion=motion\n",
    "    else:\n",
    "        \"Not supported skeleton\"\n",
    "    for i in range(len(motion) - 1, 0, -1):\n",
    "        motion[i - 1][np.where(motion[i - 1] == 0)] = motion[i][np.where(motion[i - 1] == 0)]\n",
    "\n",
    "    motion = np.stack(motion, axis=2)\n",
    "    motion = gaussian_filter1d(motion, sigma=2, axis=-1)\n",
    "    motion = motion * scale\n",
    "    \n",
    "    motion=preprocess_motion2d(motion, mean_pose, std_pose)\n",
    "    motion=motion.to(config.device)\n",
    "    return encoder(motion).cpu().detach().numpy().squeeze()\n",
    "\n",
    "def get_sliding_wins(motion,percentage,win_size,steps=1):\n",
    "    percentage.reset_index(inplace=True,drop=True)\n",
    "    sliding_win=[]\n",
    "    sliding_percent=[]\n",
    "\n",
    "    for i in percentage.tester.unique():\n",
    "        start_id=np.where(percentage.tester == i)[0][0]\n",
    "        end_id=np.where(percentage.tester == i)[0][-1]+1\n",
    "        counter=0\n",
    "        for window in percentage.percentage.iloc[start_id:end_id].rolling(window=win_size,min_periods=win_size):\n",
    "            if len(window)<win_size:\n",
    "                continue\n",
    "            else:\n",
    "                if counter%steps == 0:\n",
    "                    sliding_win.append(motion[window.index,:,:])\n",
    "                    sliding_percent.append(window.iloc[-1])\n",
    "                    counter+=1\n",
    "                else:\n",
    "                    counter+=1\n",
    "    sliding_percent=np.array(sliding_percent)\n",
    "    return(sliding_win,sliding_percent)\n",
    "\n",
    "def label_encoding(data, segment,win_size,encoder,steps=1):\n",
    "    sliding_win, sliding_percent=get_sliding_wins(data, segment,win_size,steps=steps)\n",
    "    encode_test=[]\n",
    "    for i in range(len(sliding_win)):\n",
    "        data=tl_preprocess_encode(sliding_win[i],encoder=encoder)\n",
    "        encode_test.append(data)\n",
    "    encode_test=np.array(encode_test)\n",
    "    # sim_matrix=sk.metrics.pairwise.cosine_similarity(encode_test.reshape((-1,96*3)))\n",
    "    return((encode_test, sliding_percent) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args= argparse.Namespace(name='skeleton',model_path='model/pretrained_skeleton.pth',v1='inc_deep_squat',o='inc_deep_squat',gpu_ids=0,w1=720,h1=720,transparency=False,save_frame=1,\n",
    " fps=25,color1='#a50b69#b73b87#db9dc3',max_len=480,max_frame=480)\n",
    "config.initialize(args)\n",
    "mean_pose, std_pose = get_meanpose(config)\n",
    "net = get_autoencoder(config)\n",
    "net.load_state_dict(torch.load(args.model_path))\n",
    "net.to(config.device)\n",
    "net.eval()\n",
    "encoder=nn.Sequential(*list(net.mot_encoder.children())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for task in task_list:\n",
    "    if task != 'm10':\n",
    "        continue\n",
    "    m_data=np.load('data/'+task+'.npy')\n",
    "    percentage=pd.read_csv('data/'+task+'.csv')\n",
    "    m_data=LR_mirror(m_data,percentage,LR_table,task)\n",
    "    m_data=getPoseNet(m_data)\n",
    "    for subj in s_number:\n",
    "        print(\"Motion: %s\"%task)\n",
    "        print('Testing on subject: %s'%subj)\n",
    "        X_train, y_train = np.array(m_data)[np.where(percentage['tester']!=subj),:,:][0],percentage.iloc[np.where(percentage['tester']!=subj)[0],:]\n",
    "        X_test, y_test = np.array(m_data)[np.where(percentage['tester']==subj),:,:][0],percentage.iloc[np.where(percentage['tester']==subj)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        encode_X_train_camera, sim_matrix_X_train_camera =  label_encoding(X_train, y_train,win_size,encoder,steps=1)\n",
    "\n",
    "\n",
    "        print(\"Finish encoding\")\n",
    "\n",
    "        X_train, y_train =sk.utils.shuffle(encode_X_train_camera,sim_matrix_X_train_camera)\n",
    "\n",
    "\n",
    "        print(X_train.shape)\n",
    "        print(y_train.shape)\n",
    "\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.Input(shape=(128,2,)))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        # model.add(keras.layers.LSTM(32))\n",
    "\n",
    "        model.add(keras.layers.Conv1D(32, 3, activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling1D(2))\n",
    "        model.add(keras.layers.Conv1D(64, 3, activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling1D(2))\n",
    "        model.add(keras.layers.Flatten())\n",
    "\n",
    "        # model.add(keras.layers.Dense(64))\n",
    "        model.add(keras.layers.Dense(16))\n",
    "        model.add(keras.layers.Dense(8))\n",
    "        model.add(keras.layers.Dense(4))\n",
    "        model.add(keras.layers.Dense(1,activation='sigmoid'))\n",
    "        model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=['MeanSquaredError']\n",
    "        )\n",
    "        print(model.summary())\n",
    "        model.fit(x=X_train.astype('float32'),y=y_train.astype('float32'), epochs=1000,validation_split=0.2,batch_size=50)\n",
    "        model.save('model/0516_full_full_Motion_sim_poseNet_'+task+\"_testing on_\"+subj+'.h5')\n",
    "\n",
    "        X_testcamera=np.array([camera_projet(x,np.array([0,0,0.0]),np.array([0,0.0,0])) for x in X_test])\n",
    "        encode_X_test_camera, sim_matrix_X_test_camera =  label_encoding(X_testcamera, y_test,win_size,encoder)\n",
    "\n",
    "        predict=model.predict(encode_X_test_camera)\n",
    "\n",
    "        perfor[task][subj]=sk.metrics.mean_squared_error(sim_matrix_X_test_camera,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
